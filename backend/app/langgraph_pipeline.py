"""
LangGraph + Pydantic AI ç»“åˆç¤ºä¾‹

åŸºäº pydantic-ai-demo å·¥å•åˆ†æåœºæ™¯

æ¶æ„:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    LangGraph (ç¼–æ’å±‚)                        â”‚
â”‚                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚ analyze â”‚â”€â”€â–¶â”‚ enrich   â”‚â”€â”€â–¶â”‚ respondâ”‚â”€â”€â–¶| escalate â”‚    â”‚
â”‚  â”‚ (å·¥å•)  â”‚   â”‚ (è¡¥å……)   â”‚   â”‚ (å›å¤) â”‚   â”‚ (å‡çº§)   â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚       â”‚              â”‚                          â”‚          â”‚
â”‚       â”‚         æœ‰è®¢å•å·?                   éœ€äººå·¥?        â”‚
â”‚       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚
â”‚                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚
                          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  Pydantic AI (æ‰§è¡Œå±‚)                        â”‚
â”‚                                                             â”‚
â”‚  æ¯ä¸ª Node å†…éƒ¨æ˜¯ä¸€ä¸ª PydanticAI Agent:                     â”‚
â”‚  - ç»“æ„åŒ–è¾“å…¥/è¾“å‡º                                          â”‚
â”‚  - è‡ªåŠ¨ç±»å‹æ ¡éªŒ                                             â”‚
â”‚  - å†…ç½®é‡è¯•æœºåˆ¶                                             â”‚
â”‚                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
"""

from typing import Annotated, Optional
from pydantic import BaseModel, Field
from pydantic_ai import Agent, RunContext
from langgraph.graph import StateGraph, END
from langgraph.graph.message import add_messages
import operator
import time

# å¯¼å…¥ç°æœ‰æ¨¡å‹
from .models import TicketCategory, UrgencyLevel


# ============================================================
# Part 1: LangGraph å…¨å±€çŠ¶æ€ (Pydantic å®šä¹‰)
# ============================================================

class GraphState(BaseModel):
    """
    LangGraph å…¨å±€çŠ¶æ€
    
    ä½¿ç”¨ Pydantic BaseModel ç¡®ä¿ç±»å‹å®‰å…¨
    """
    # åŸå§‹ç”¨æˆ·è¾“å…¥
    user_input: str = Field(default="")
    
    # è§£æåçš„å·¥å•ä¿¡æ¯ (æ¥è‡ª Pydantic AI)
    category: Optional[TicketCategory] = None
    urgency: Optional[UrgencyLevel] = None
    product: Optional[str] = None
    order_id: Optional[str] = None
    summary: Optional[str] = None
    confidence: float = 0.0
    
    # è¡¥å……ä¿¡æ¯
    order_status: Optional[str] = None
    order_product: Optional[str] = None
    
    # ç”Ÿæˆçš„å›å¤
    suggested_response: Optional[str] = None
    
    # æ˜¯å¦éœ€è¦äººå·¥ä»‹å…¥
    needs_escalation: bool = False
    escalation_reason: Optional[str] = None
    
    # æµç¨‹è¿½è¸ª
    messages: Annotated[list, add_messages] = Field(default_factory=list)
    current_node: str = Field(default="")
    iteration: Annotated[int, operator.add] = Field(default=0)


# ============================================================
# Part 2: Pydantic AI Agents (æ¯ä¸ª Node å¯¹åº”ä¸€ä¸ª Agent)
# ============================================================

# --- Agent 1: å·¥å•åˆ†æ ---

class AnalyzeOutput(BaseModel):
    """å·¥å•åˆ†æç»“æœ"""
    category: TicketCategory = Field(description="å·¥å•åˆ†ç±»")
    urgency: UrgencyLevel = Field(description="ç´§æ€¥ç¨‹åº¦")
    product: str = Field(description="äº§å“åç§°", min_length=1)
    order_id: Optional[str] = Field(
        None, 
        pattern=r"^[A-Z]{2}\d{8}$",
        description="è®¢å•å·ï¼ˆå¦‚æœæœ‰ï¼‰"
    )
    summary: str = Field(description="é—®é¢˜æ‘˜è¦", min_length=10)
    confidence: float = Field(description="ç½®ä¿¡åº¦", ge=0.0, le=1.0)


analyze_agent = Agent(
    "openai:gpt-4o-mini",
    name="ticket_analyzer",
    output_type=AnalyzeOutput,
    system_prompt="""ä½ æ˜¯å·¥å•åˆ†æä¸“å®¶ã€‚
åˆ†æç”¨æˆ·çš„é—®é¢˜æè¿°ï¼Œæå–ï¼š
- category: complaint/inquiry/suggestion/bug/refund/other
- urgency: P0(ç´§æ€¥)/P1(é«˜)/P2(ä¸­)/P3(ä½)
- product: æ¶‰åŠçš„äº§å“
- order_id: è®¢å•å·ï¼ˆæ ¼å¼å¦‚ AB12345678ï¼Œæ²¡æœ‰åˆ™ä¸º nullï¼‰
- summary: 10-100å­—æ‘˜è¦
- confidence: 0-1 ç½®ä¿¡åº¦"""
)


# --- Agent 2: è®¢å•ä¿¡æ¯è¡¥å…… ---

class EnrichInput(BaseModel):
    """è¡¥å……ä¿¡æ¯è¾“å…¥"""
    order_id: str = Field(description="è®¢å•å·")


class EnrichOutput(BaseModel):
    """è¡¥å……ä¿¡æ¯è¾“å‡º"""
    order_status: str = Field(description="è®¢å•çŠ¶æ€")
    order_product: str = Field(description="è®¢å•äº§å“")
    days_since_order: int = Field(description="è·ä¸‹å•å¤©æ•°", ge=0)


enrich_agent = Agent(
    "openai:gpt-4o-mini",
    name="order_enricher",
    output_type=EnrichOutput,
    system_prompt="""ä½ æ˜¯è®¢å•æŸ¥è¯¢åŠ©æ‰‹ã€‚
æ ¹æ®è®¢å•å·ï¼Œè¿”å›ï¼š
- order_status: è®¢å•çŠ¶æ€
- order_product: è®¢å•äº§å“
- days_since_order: è·ä¸‹å•å¤©æ•°

ï¼ˆå®é™…åœºæ™¯ä¸­ä¼šè°ƒç”¨çœŸå®æ•°æ®åº“/APIï¼‰"""
)


# --- Agent 3: å›å¤ç”Ÿæˆ ---

class RespondInput(BaseModel):
    """å›å¤ç”Ÿæˆè¾“å…¥"""
    category: TicketCategory
    urgency: UrgencyLevel
    product: str
    summary: str
    order_status: Optional[str] = None


class RespondOutput(BaseModel):
    """å›å¤ç”Ÿæˆè¾“å‡º"""
    response: str = Field(description="å®¢æœå›å¤", min_length=20)
    tone: str = Field(description="è¯­æ°”: professional/friendly/apologetic")
    next_steps: list[str] = Field(description="åç»­æ­¥éª¤", min_length=1)


respond_agent = Agent(
    "openai:gpt-4o-mini",
    name="response_generator",
    output_type=RespondOutput,
    system_prompt="""ä½ æ˜¯å®¢æœå›å¤æ’°å†™ä¸“å®¶ã€‚
æ ¹æ®å·¥å•ä¿¡æ¯ï¼Œç”Ÿæˆï¼š
- response: ä¸“ä¸šã€æœ‰åŒç†å¿ƒçš„å›å¤ï¼ˆ20-200å­—ï¼‰
- tone: professional/friendly/apolothetic
- next_steps: åç»­å¤„ç†æ­¥éª¤åˆ—è¡¨"""
)


# --- Agent 4: å‡çº§åˆ¤æ–­ ---

class EscalateInput(BaseModel):
    """å‡çº§åˆ¤æ–­è¾“å…¥"""
    category: TicketCategory
    urgency: UrgencyLevel
    confidence: float
    order_status: Optional[str] = None


class EscalateOutput(BaseModel):
    """å‡çº§åˆ¤æ–­è¾“å‡º"""
    needs_escalation: bool = Field(description="æ˜¯å¦éœ€è¦äººå·¥")
    reason: Optional[str] = Field(None, description="å‡çº§åŸå› ")
    priority: str = Field(description="ä¼˜å…ˆçº§: low/medium/high")


escalate_agent = Agent(
    "openai:gpt-4o-mini",
    name="escalation_decider",
    output_type=EscalateOutput,
    system_prompt="""ä½ æ˜¯å®¢æœæµç¨‹å†³ç­–è€…ã€‚
åˆ¤æ–­æ˜¯å¦éœ€è¦äººå·¥ä»‹å…¥ï¼š
- P0/P1 ç´§æ€¥ â†’ éœ€è¦
- confidence < 0.7 â†’ éœ€è¦
- æŠ•è¯‰ç±» + è®¢å•é—®é¢˜ â†’ éœ€è¦
å…¶ä»–æƒ…å†µè‡ªåŠ¨å¤„ç†ã€‚"""
)


# ============================================================
# Part 3: LangGraph Nodes (ç¼–æ’å±‚è°ƒç”¨ Pydantic AI)
# ============================================================

async def analyze_node(state: dict) -> dict:
    """
    Node 1: å·¥å•åˆ†æ
    
    LangGraph è°ƒç”¨ Pydantic AI Agent
    - è¾“å…¥: ç”¨æˆ·åŸå§‹æè¿°
    - è¾“å‡º: ç»“æ„åŒ–å·¥å•ä¿¡æ¯ (AnalyzeOutput)
    """
    user_input = state["user_input"]
    
    # è°ƒç”¨ Pydantic AI Agent
    result = await analyze_agent.run(f"åˆ†æå·¥å•: {user_input}")
    output: AnalyzeOutput = result.data  # ç±»å‹å®‰å…¨!
    
    # æ›´æ–° LangGraph çŠ¶æ€
    return {
        "category": output.category,
        "urgency": output.urgency,
        "product": output.product,
        "order_id": output.order_id,
        "summary": output.summary,
        "confidence": output.confidence,
        "messages": [f"âœ… åˆ†æå®Œæˆ: {output.category.value} | {output.urgency.value} | ç½®ä¿¡åº¦ {output.confidence:.0%}"],
        "current_node": "analyze",
        "iteration": 1,
    }


async def enrich_node(state: dict) -> dict:
    """
    Node 2: è®¢å•ä¿¡æ¯è¡¥å……
    
    å¦‚æœæœ‰è®¢å•å·ï¼ŒæŸ¥è¯¢è¡¥å……ä¿¡æ¯
    """
    order_id = state.get("order_id")
    
    if not order_id:
        return {
            "messages": ["â­ï¸ æ— è®¢å•å·ï¼Œè·³è¿‡è¡¥å……"],
            "current_node": "enrich",
            "iteration": 1,
        }
    
    # è°ƒç”¨ Pydantic AI Agent
    input_data = EnrichInput(order_id=order_id)
    result = await enrich_agent.run(f"æŸ¥è¯¢è®¢å•: {input_data.order_id}")
    output: EnrichOutput = result.data
    
    return {
        "order_status": output.order_status,
        "order_product": output.order_product,
        "messages": [f"ğŸ“¦ è®¢å•ä¿¡æ¯: {output.order_status} | {output.order_product}"],
        "current_node": "enrich",
        "iteration": 1,
    }


async def respond_node(state: dict) -> dict:
    """
    Node 3: ç”Ÿæˆå›å¤
    
    æ ¹æ®å·¥å•ä¿¡æ¯ç”Ÿæˆå®¢æœå›å¤
    """
    # æ„é€  Pydantic è¾“å…¥ï¼ˆè‡ªåŠ¨æ ¡éªŒï¼‰
    input_data = RespondInput(
        category=state["category"],
        urgency=state["urgency"],
        product=state["product"],
        summary=state["summary"],
        order_status=state.get("order_status"),
    )
    
    # è°ƒç”¨ Agent
    prompt = f"""
    åˆ†ç±»: {input_data.category.value}
    ç´§æ€¥: {input_data.urgency.value}
    äº§å“: {input_data.product}
    æ‘˜è¦: {input_data.summary}
    è®¢å•çŠ¶æ€: {input_data.order_status or 'æ— '}
    """
    result = await respond_agent.run(prompt)
    output: RespondOutput = result.data
    
    return {
        "suggested_response": output.response,
        "messages": [f"ğŸ’¬ ç”Ÿæˆå›å¤: {output.tone} | {len(output.next_steps)} ä¸ªåç»­æ­¥éª¤"],
        "current_node": "respond",
        "iteration": 1,
    }


async def escalate_node(state: dict) -> dict:
    """
    Node 4: å‡çº§åˆ¤æ–­
    
    å†³å®šæ˜¯å¦éœ€è¦äººå·¥ä»‹å…¥
    """
    input_data = EscalateInput(
        category=state["category"],
        urgency=state["urgency"],
        confidence=state["confidence"],
        order_status=state.get("order_status"),
    )
    
    prompt = f"""
    åˆ†ç±»: {input_data.category.value}
    ç´§æ€¥: {input_data.urgency.value}
    ç½®ä¿¡åº¦: {input_data.confidence}
    è®¢å•çŠ¶æ€: {input_data.order_status or 'æ— '}
    """
    result = await escalate_agent.run(prompt)
    output: EscalateOutput = result.data
    
    return {
        "needs_escalation": output.needs_escalation,
        "escalation_reason": output.reason,
        "messages": [f"{'ğŸš¨ å‡çº§äººå·¥' if output.needs_escalation else 'âœ… è‡ªåŠ¨å¤„ç†'} | ä¼˜å…ˆçº§: {output.priority}"],
        "current_node": "escalate",
        "iteration": 1,
    }


# ============================================================
# Part 4: LangGraph è·¯ç”±é€»è¾‘ (æ¡ä»¶è¾¹)
# ============================================================

def should_enrich(state: dict) -> str:
    """
    æ¡ä»¶è¾¹: æ˜¯å¦éœ€è¦æŸ¥è¯¢è®¢å•
    
    åŸºäº Pydantic æ ¡éªŒåçš„ state åšå†³ç­–
    """
    order_id = state.get("order_id")
    if order_id:
        return "enrich"
    return "respond"


# ============================================================
# Part 5: æ„å»º Graph
# ============================================================

def build_ticket_pipeline() -> StateGraph:
    """æ„å»ºå·¥å•å¤„ç†æµæ°´çº¿"""
    
    # ä½¿ç”¨ Pydantic schema å®šä¹‰ Graph çŠ¶æ€
    graph = StateGraph(GraphState.model_json_schema())
    
    # æ·»åŠ èŠ‚ç‚¹ (æ¯ä¸ªèŠ‚ç‚¹å†…éƒ¨æ˜¯ Pydantic AI Agent)
    graph.add_node("analyze", analyze_node)
    graph.add_node("enrich", enrich_node)
    graph.add_node("respond", respond_node)
    graph.add_node("escalate", escalate_node)
    
    # å…¥å£
    graph.set_entry_point("analyze")
    
    # æ¡ä»¶è¾¹: analyze -> enrich (æœ‰è®¢å•) / respond (æ— è®¢å•)
    graph.add_conditional_edges(
        "analyze",
        should_enrich,
        {
            "enrich": "enrich",
            "respond": "respond",
        }
    )
    
    # å›ºå®šè¾¹
    graph.add_edge("enrich", "respond")
    graph.add_edge("respond", "escalate")
    graph.add_edge("escalate", END)
    
    return graph.compile()


# ============================================================
# Part 6: è¿è¡Œç¤ºä¾‹
# ============================================================

async def process_ticket(user_input: str) -> dict:
    """
    å¤„ç†å·¥å•çš„å®Œæ•´æµç¨‹
    
    LangGraph ç¼–æ’ + Pydantic AI æ‰§è¡Œ
    """
    app = build_ticket_pipeline()
    
    initial_state = {
        "user_input": user_input,
        "messages": [],
        "iteration": 0,
    }
    
    print("=" * 60)
    print(f"ğŸ“¥ è¾“å…¥: {user_input}")
    print("=" * 60)
    
    # æµå¼æ‰§è¡Œ
    final_state = None
    async for event in app.astream(initial_state):
        for node_name, node_output in event.items():
            print(f"\nâ–¶ {node_name}: {node_output.get('messages', [])}")
            final_state = node_output
    
    print("\n" + "=" * 60)
    print("ğŸ“‹ æœ€ç»ˆç»“æœ:")
    print(f"  åˆ†ç±»: {final_state.get('category')}")
    print(f"  ç´§æ€¥: {final_state.get('urgency')}")
    print(f"  å›å¤: {final_state.get('suggested_response')}")
    print(f"  å‡çº§: {final_state.get('needs_escalation')}")
    print("=" * 60)
    
    return final_state


if __name__ == "__main__":
    import asyncio
    
    # æµ‹è¯•ç”¨ä¾‹
    test_cases = [
        "æˆ‘ä¹°çš„æ™ºèƒ½æ‰‹è¡¨ AB12345678 æ”¶åˆ°å°±åäº†ï¼Œè¦æ±‚é€€æ¬¾ï¼",
        "è¯·é—®ä½ ä»¬æœ‰å„¿ç«¥æ‰‹è¡¨å—ï¼Ÿæƒ³ç»™å­©å­ä¹°ä¸ª",
        "APP é—ªé€€ï¼Œç™»å½•ä¸äº†ï¼Œè®¢å•å· CD87654321",
    ]
    
    for case in test_cases:
        asyncio.run(process_ticket(case))
        print("\n")
